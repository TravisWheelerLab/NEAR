# -*- coding: utf-8 -*-
"""Hit evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N-QIEdmTd8m8p9cl6tQwwYt-4NEQh-81
"""

import re

import matplotlib.pyplot as plt
import torch
from google.colab import drive

drive.mount('/content/drive')

!cp ./drive/MyDrive/data/normal_hmmer_hits.txt ./
!cp ./drive/MyDrive/data/max_hmmer_hits.txt ./
!cp ./drive/MyDrive/data/hits.txt ./

def get_hmmer_hits(file_path):
  queries = dict()
  with open(file_path, 'r') as file:
    for line in file:
      line = line.strip()
      if len(line) == 0:
        continue
      if line[0] == '#':
        continue
      line = re.split(" +", line)
      target = line[0]
      query = line[2]
      e_value = float(line[4])
      score = float(line[6])

      if query not in queries:
        queries[query] = dict()
      
      queries[query][target] = (e_value, score)
    
    return queries

def get_model_hits(file_path):
  queries = dict()
  with open(file_path, 'r') as file:
    lines = file.readlines()
   # print("lines: ",len(lines))
    for line in lines:
      line = line.strip()
      line = line.split(" ")
      query = line[0]
      key = line[1]
      value = float(line[2])

      # print(query, key )

      if query not in queries:
        queries[query] = dict()
      queries[query][key] = value
  return queries

def filtered_hits(queries, threshold):
  filtered_queries = dict()
  for key in queries:
    filtered_queries[key] = dict()
    for tkey in queries[key]:
      if queries[key][tkey] <= threshold:
        filtered_queries[key][tkey] = True
  return filtered_queries

def number_of_hits(queries):
  num = 0
  for key in queries:
    num += len(queries[key])
  
  return num

def union_hits(query1, query2):
  queries = dict()
  for qkey in query1:
    queries[qkey] = dict()
    if qkey in query2:
      for tkey in query1[qkey]:
        if tkey in query2[qkey]:
          queries[qkey][tkey] = True
  
  return queries

def union_queries(primary, secondary):
  new_secondary = dict()
  for qkey in primary:
    if qkey in secondary:
      new_secondary[qkey] = secondary[qkey]
    else:
      secondary[qkey] = dict()
  return new_secondary


def scores(hmmer, other):
  found = []
  not_found = []
  for qkey in other:
    
    for tkey in hmmer[qkey]:
      if tkey in other[qkey]:
        found.append(hmmer[qkey][tkey][1])
      else:
        not_found.append(hmmer[qkey][tkey][1])
  return found, not_found

def all_our_scores(hits):
  values = []
  for qkey in hits:
    for tkey in hits[qkey]:
      values.append(hits[qkey][tkey])

  return torch.tensor(values)

max_hits = get_hmmer_hits("max_hmmer_hits.txt")
normal_hits = get_hmmer_hits("normal_hmmer_hits.txt")
our_hits = get_model_hits("hits.txt")

print(len(max_hits))
print(len(normal_hits))

print(number_of_hits(max_hits))
print(number_of_hits(normal_hits))
print(number_of_hits(our_hits))
#print(number_of_hits(union_hits(max_hits, normal_hits)))
#print(number_of_hits(union_hits(normal_hits, max_hits)))
#print(number_of_hits(union_hits(normal_hits, our_hits)))

values = all_our_scores(our_hits)
values, _ = torch.sort(values)
#plt.scatter(torch.arange(len(values)), values)
#plt.show()

small_max = union_queries(our_hits, max_hits)
small_normal = union_queries(our_hits, normal_hits)




our_filter = filtered_hits(our_hits, 0.4)
filtration = 1.0 - (number_of_hits(our_filter) / number_of_hits(our_hits))

print(number_of_hits(our_filter), '=', filtration)
print('--')
print("max:",number_of_hits(small_max), number_of_hits(union_hits(our_filter, small_max)))
print("normal:", number_of_hits(small_normal), number_of_hits(union_hits(our_filter, small_normal)))

filt_value = 0.73 #0.740 gives great results


our_filter = filtered_hits(our_hits, filt_value)
small_max = union_queries(our_hits, max_hits)
small_normal = union_queries(our_hits, normal_hits)

filtration = 1.0 - (number_of_hits(our_filter) / number_of_hits(our_hits))

fig, axs = plt.subplots(3, 2)
fig.set_size_inches(15., 15)

#small_max = union_queries(our_filter, max_hits)
#small_normal = union_queries(our_filter, normal_hits)


found, not_found = scores(max_hits, our_filter)

recall = len(found) / (len(found) + len(not_found))

found, _ = torch.sort(torch.tensor(found))
not_found, _ = torch.sort(torch.tensor(not_found))

axs[0,0].hist([found, not_found], stacked=True, bins=10, range=(0,40), label=['found', 'not_found'])
#axs[0,0].hist(not_found, bins=10, color=(1,0,0,0.5),range=(0,80), label='not found')
axs[0,0].text(25, 2000, "filtration: " + str(filtration) + "\nrecall: " + str(recall))


axs[0,0].legend()


axs[0,1].hist([found[found > 10], not_found[not_found > 10]], stacked=True, bins=10, range=(10,40), label=['found', 'not_found'])
#axs[0,1].hist(not_found[not_found > 10], bins=10, color=(1,0,0,0.5),range=(10,80), label='not found')
axs[0,1].legend()
recall = len(found[found > 10]) / (len(found[found > 10]) + len(not_found[not_found > 10]))
axs[0,1].text(25, 100, "filtration: " + str(filtration) + "\nrecall: " + str(recall))

our_filter = filtered_hits(our_hits, filt_value)


#small_max = union_queries(our_filter, max_hits)
#small_normal = union_queries(our_filter, normal_hits)


found, not_found = scores(normal_hits, our_filter)
recall = len(found) / (len(found) + len(not_found))
found, _ = torch.sort(torch.tensor(found))
not_found, _ = torch.sort(torch.tensor(not_found))

axs[1,0].hist([found, not_found], stacked=True, bins=10, range=(0,40), label=['found', 'not_found'])
axs[1,0].text(25, 2000, "filtration: " + str(filtration) + "\nrecall: " + str(recall))
axs[1,0].legend()

axs[1,1].hist([found[found > 10], not_found[not_found > 10]], stacked=True, bins=10, range=(10,40), label=['found', 'not_found'])
axs[1,1].legend()

recall = len(found[found > 10]) / (len(found[found > 10]) + len(not_found[not_found > 10]))
#axs[1,1].text(25, 100, "filtration: " + str(filtration) + "\nrecall: " + str(recall))
fig.show()

found, not_found = scores(max_hits, small_normal)
recall = len(found) / (len(found) + len(not_found))
found, _ = torch.sort(torch.tensor(found))
not_found, _ = torch.sort(torch.tensor(not_found))

filtration=0.995572
axs[2,0].hist([found, not_found], stacked=True, bins=10, range=(0,40), label=['found', 'not_found'])
axs[2,0].text(25, 2000, "filtration: " + str(filtration) + "\nrecall: " + str(recall), label='not found')
axs[2,0].legend()
axs[2,1].hist([found[found > 10], not_found[not_found > 10]], stacked=True, bins=10, range=(10,40), label=['found', 'not_found'])
axs[2,1].legend()

recall = len(found[found > 10]) / (len(found[found > 10]) + len(not_found[not_found > 10]))
#axs[2,1].text(25, 100, "filtration: " + str(filtration) + "\nrecall: " + str(recall))


axs[0,0].set_ylabel('Sequences found')
axs[0,1].set_ylabel('Sequences found')
axs[1,0].set_ylabel('Sequences found')
axs[1,1].set_ylabel('Sequences found')
axs[2,0].set_ylabel('Sequences found')
axs[2,1].set_ylabel('Sequences found')

axs[0,0].set_xlabel('HMMER score')
axs[0,1].set_xlabel('HMMER score')
axs[1,0].set_xlabel('HMMER score')
axs[1,1].set_xlabel('HMMER score')
axs[2,0].set_xlabel('HMMER score')
axs[2,1].set_xlabel('HMMER score')

fig.show()



def one_not_other(one, other):
  queries = dict()
  not_represented = 0
  for qkey in one:
    if qkey not in other:
      queries.append(one.qkey)
      not_represented += 1
    else:
      queries[qkey] = dict()
      for tkey in one[qkey]:
        if tkey not in other[qkey]:
          queries[qkey][tkey] = True
  return queries, not_represented


outside, not_repped = one_not_other(small_normal, our_filter)
print(outside['UniRef90_A0A7Y9Z3K1'])

query UniRef90_A0A7Y9Z3K1
target UniRef90_A0A7W5DIC2